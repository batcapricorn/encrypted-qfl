{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15a87107",
   "metadata": {},
   "source": [
    "# Demo – Integrating FHE into QFL\n",
    "This notebook provides a glimpse into our project and demonstrates how to run QFL experiments that incorporate FHE using this repository.\n",
    "\n",
    "## Setup\n",
    "First, we import all necessary libraries and define the settings for our experiment run. All options are described in more detail in our [README](README.md). Please note that we set `\"layers_to_encrypt\": [\"classifier.0.weight\"]`, meaning we will only encrypt the layer `classifier.0.weight`. This is for demonstration purposes only, to reduce overhead since the notebook is intended to run locally. We will run a simple QML model using FHE. If you adapt the model type, you may need to adjust `layers_to_encrypt` accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94500f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "settings = {\n",
    "    \"wandb_project\": \"qfl-playground\",\n",
    "    \"data_path\": \"data-tiny/\",\n",
    "    \"dataset\": \"MRI\",\n",
    "    \"seed\": 0,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_epochs\": 10,\n",
    "    \"batch_size\": 10,\n",
    "    \"splitter\": 10,\n",
    "    \"device\": \"cpu\",\n",
    "    \"number_clients\": 1,\n",
    "    \"export_results_path\": \"results/\",\n",
    "    \"matrix_export\": True,\n",
    "    \"roc_export\": True,\n",
    "    \"min_fit_clients\": 1,\n",
    "    \"min_avail_clients\": 1,\n",
    "    \"min_eval_clients\": 1,\n",
    "    \"rounds\": 3,\n",
    "    \"frac_fit\": 1.0,\n",
    "    \"frac_eval\": 0.5,\n",
    "    \"lr\": 1e-3,\n",
    "    \"private_key_path\": \"private_key.pkl\",\n",
    "    \"public_key_path\": \"public_key.pkl\",\n",
    "    \"model_checkpoint_path\": \"model_checkpoint.pt\",\n",
    "    \"encrypted_model_checkpoint_path\": \"encrypted_model_checkpoint.pkl\",\n",
    "    \"layers_to_encrypt\": [\"classifier.0.weight\"],\n",
    "    \"n_qubits\": 4,\n",
    "    \"n_layers\": 6,\n",
    "}\n",
    "\n",
    "with open(\"settings.yaml\", \"w\") as file:\n",
    "    yaml.dump(settings, file, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce652423",
   "metadata": {},
   "source": [
    "## Weights and Biases\n",
    "Metrics are pushed to [Weights & Biases](https://wandb.ai/). You may want to define your API key here to browse statistics using their dashboards. However, to showcase our project, we will simply switch to offline mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f4e11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/workspaces/encrypted-qfl/wandb/offline-run-20251114_122722-ie4fv15y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/encrypted-qfl-demo/uncategorized/runs/ie4fv15y?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x74e649aeee40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "wandb.init(\"encrypted-qfl-demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715988cc",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "It's time — we will make the bash script [experiment.sh](./scripts/experiment.sh) executable and run it using the parameters `cnn-qnn` and `--he`. This will train a QML model that leverages basic entangler layers and CKKS for parameter encryption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ed7ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = subprocess.run(\n",
    "    [\"chmod\", \"+x\", \"./scripts/experiment.sh\"], stdout=subprocess.PIPE\n",
    ")\n",
    "print(result.stdout.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be70fe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Tracking run with wandb version 0.23.0\n",
      "wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
      "wandb: Run data is saved locally in /workspaces/encrypted-qfl/wandb/offline-run-20251114_122753-hf1xpc3f\n",
      "INFO flwr 2025-11-14 12:27:58,928 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "INFO flwr 2025-11-14 12:27:58,984 | app.py:175 | Flower ECE: gRPC server running (3 rounds), SSL is disabled\n",
      "INFO flwr 2025-11-14 12:27:58,985 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2025-11-14 12:27:58,986 | server.py:272 | Using initial parameters provided by strategy\n",
      "INFO flwr 2025-11-14 12:27:58,987 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2025-11-14 12:27:58,988 | server.py:104 | FL starting\n",
      "wandb: Tracking run with wandb version 0.23.0\n",
      "wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
      "wandb: Run data is saved locally in /workspaces/encrypted-qfl/wandb/offline-run-20251114_122841-w63vtl0o\n",
      "INFO flwr 2025-11-14 12:28:43,159 | grpc.py:49 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2025-11-14 12:28:43,165 | connection.py:42 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2025-11-14 12:28:43,169 | connection.py:42 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flwr 2025-11-14 12:28:43,175 | connection.py:42 | ChannelConnectivity.READY\n",
      "DEBUG flwr 2025-11-14 12:28:43,178 | server.py:222 | fit_round 1: strategy sampled 1 clients (out of 1)\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:29<00:00,  2.94s/it]\n",
      "DEBUG flwr 2025-11-14 12:29:18,524 | server.py:236 | fit_round 1 received 1 results and 0 failures\n",
      "WARNING flwr 2025-11-14 12:29:22,220 | server.py:339 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2025-11-14 12:29:25,099 | server.py:173 | evaluate_round 1: strategy sampled 1 clients (out of 1)\n",
      "/root/.local/share/virtualenvs/encrypted-qfl-VgupAGw-/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:1201: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/.local/share/virtualenvs/encrypted-qfl-VgupAGw-/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:1201: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "DEBUG flwr 2025-11-14 12:29:33,882 | server.py:187 | evaluate_round 1 received 1 results and 0 failures\n",
      "DEBUG flwr 2025-11-14 12:29:33,977 | server.py:222 | fit_round 2: strategy sampled 1 clients (out of 1)\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:24<00:00,  2.44s/it]\n",
      "DEBUG flwr 2025-11-14 12:30:14,732 | server.py:236 | fit_round 2 received 1 results and 0 failures\n",
      "DEBUG flwr 2025-11-14 12:30:22,201 | server.py:173 | evaluate_round 2: strategy sampled 1 clients (out of 1)\n",
      "/root/.local/share/virtualenvs/encrypted-qfl-VgupAGw-/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/root/.local/share/virtualenvs/encrypted-qfl-VgupAGw-/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:1201: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/.local/share/virtualenvs/encrypted-qfl-VgupAGw-/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:1201: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "DEBUG flwr 2025-11-14 12:30:24,729 | server.py:187 | evaluate_round 2 received 1 results and 0 failures\n",
      "DEBUG flwr 2025-11-14 12:30:24,762 | server.py:222 | fit_round 3: strategy sampled 1 clients (out of 1)\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:33<00:00,  3.39s/it]\n",
      "DEBUG flwr 2025-11-14 12:31:06,652 | server.py:236 | fit_round 3 received 1 results and 0 failures\n",
      "DEBUG flwr 2025-11-14 12:31:10,378 | server.py:173 | evaluate_round 3: strategy sampled 1 clients (out of 1)\n",
      "/root/.local/share/virtualenvs/encrypted-qfl-VgupAGw-/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/root/.local/share/virtualenvs/encrypted-qfl-VgupAGw-/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:1201: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/.local/share/virtualenvs/encrypted-qfl-VgupAGw-/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:1201: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "DEBUG flwr 2025-11-14 12:31:11,653 | server.py:187 | evaluate_round 3 received 1 results and 0 failures\n",
      "INFO flwr 2025-11-14 12:31:11,655 | server.py:153 | FL finished in 192.66474840599994\n",
      "INFO flwr 2025-11-14 12:31:11,667 | app.py:225 | app_fit: losses_distributed [(1, 1.2789853811264038), (2, 1.2843776941299438), (3, 1.2613680362701416)]\n",
      "INFO flwr 2025-11-14 12:31:11,667 | app.py:226 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2025-11-14 12:31:11,667 | app.py:227 | app_fit: metrics_distributed {'accuracy': [(1, 100.0), (2, 42.857142857142854), (3, 28.57142857142857)], 'recalls': [(1, 1.0), (2, 0.20833333333333331), (3, 0.14583333333333331)], 'precisions': [(1, 1.0), (2, 0.5), (3, 0.5)], 'f1s': [(1, 1.0), (2, 0.29166666666666663), (3, 0.225)]}\n",
      "INFO flwr 2025-11-14 12:31:11,668 | app.py:228 | app_fit: losses_centralized []\n",
      "INFO flwr 2025-11-14 12:31:11,668 | app.py:229 | app_fit: metrics_centralized {}\n",
      "DEBUG flwr 2025-11-14 12:31:11,707 | connection.py:139 | gRPC channel closed\n",
      "INFO flwr 2025-11-14 12:31:11,708 | app.py:215 | Disconnect and shut down\n",
      "wandb: Tracking run with wandb version 0.23.0\n",
      "wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
      "wandb: Run data is saved locally in /workspaces/encrypted-qfl/wandb/offline-run-20251114_123116-ejcb4e8d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANDB_RUN_GROUP set to: FHE-cnn-qnn-0d54042f\n",
      "Starting Flower server...\n",
      "Server PID: 34441\n",
      "Attaching to process 34441\n",
      "Is the client context private? Yes\n",
      "Is the server context private? No\n",
      "get public key :  results/FHE-cnn-qnn-0d54042f/public_key.pkl\n",
      "MRI\n",
      "The training set is created for the classes : ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
      "flwr 1.5.0\n",
      "numpy 1.26.4\n",
      "torch 2.8.0+cpu\n",
      "torchvision 0.23.0+cpu\n",
      "Training on cpu\n",
      "Starting flowerserver\n",
      "Starting client 0 with model cnn-qnn...\n",
      "New Client PID: 34613\n",
      "Attaching to process 34613\n",
      "MRI\n",
      "The training set is created for the classes : ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
      "Run with homomorphic encryption\n",
      "Starting flowerclient\n",
      "[Client 0, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '10', 'server_round': 1, 'local_epochs': 10}\n",
      "Updated trainable model parameters\n",
      "\tTrain Epoch: 1 \tTrain_loss: 1.4605 | Train_acc: 20.0000 % | Validation_loss: 1.1500 | Validation_acc: 57.1429 %\n",
      "\tTrain Epoch: 2 \tTrain_loss: 1.4399 | Train_acc: 20.0000 % | Validation_loss: 1.1861 | Validation_acc: 57.1429 %\n",
      "\tTrain Epoch: 3 \tTrain_loss: 1.4286 | Train_acc: 17.5000 % | Validation_loss: 1.2120 | Validation_acc: 57.1429 %\n",
      "\tTrain Epoch: 4 \tTrain_loss: 1.4187 | Train_acc: 20.0000 % | Validation_loss: 1.2318 | Validation_acc: 57.1429 %\n",
      "\tTrain Epoch: 5 \tTrain_loss: 1.4088 | Train_acc: 20.0000 % | Validation_loss: 1.2512 | Validation_acc: 57.1429 %\n",
      "\tTrain Epoch: 6 \tTrain_loss: 1.3988 | Train_acc: 21.2500 % | Validation_loss: 1.2684 | Validation_acc: 57.1429 %\n",
      "\tTrain Epoch: 7 \tTrain_loss: 1.3870 | Train_acc: 20.0000 % | Validation_loss: 1.2786 | Validation_acc: 71.4286 %\n",
      "\tTrain Epoch: 8 \tTrain_loss: 1.3748 | Train_acc: 35.0000 % | Validation_loss: 1.2806 | Validation_acc: 85.7143 %\n",
      "\tTrain Epoch: 9 \tTrain_loss: 1.3656 | Train_acc: 51.2500 % | Validation_loss: 1.2829 | Validation_acc: 100.0000 %\n",
      "\tTrain Epoch: 10 \tTrain_loss: 1.3555 | Train_acc: 42.5000 % | Validation_loss: 1.2790 | Validation_acc: 100.0000 %\n",
      "save graph in  results/FHE-cnn-qnn-0d54042f\n",
      "Skipping encryption of layer: features.0.weight\n",
      "Skipping encryption of layer: features.0.bias\n",
      "Skipping encryption of layer: features.3.weight\n",
      "Skipping encryption of layer: features.3.bias\n",
      "Encrypting layer: classifier.0.weight\n",
      "Skipping encryption of layer: classifier.0.bias\n",
      "Skipping encryption of layer: classifier.2.weight\n",
      "Skipping encryption of layer: classifier.2.bias\n",
      "Skipping encryption of layer: classifier.3.weights\n",
      "Skipping encryption of layer: classifier.4.weight\n",
      "Skipping encryption of layer: classifier.4.bias\n",
      "Saving round 1 aggregated_parameters...\n",
      "['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.2.weight', 'classifier.2.bias', 'classifier.3.weights', 'classifier.4.weight', 'classifier.4.bias']\n",
      "Number of aggregated parameters: 11\n",
      "[Client 0] evaluate, config: {}\n",
      "Updated trainable model parameters\n",
      "[Client 0, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '10', 'server_round': 2, 'local_epochs': 10}\n",
      "Updated trainable model parameters\n",
      "\tTrain Epoch: 1 \tTrain_loss: 1.3642 | Train_acc: 36.2500 % | Validation_loss: 1.3336 | Validation_acc: 71.4286 %\n",
      "\tTrain Epoch: 2 \tTrain_loss: 1.3423 | Train_acc: 35.0000 % | Validation_loss: 1.2977 | Validation_acc: 85.7143 %\n",
      "\tTrain Epoch: 3 \tTrain_loss: 1.3344 | Train_acc: 46.2500 % | Validation_loss: 1.2750 | Validation_acc: 100.0000 %\n",
      "\tTrain Epoch: 4 \tTrain_loss: 1.3271 | Train_acc: 42.5000 % | Validation_loss: 1.2873 | Validation_acc: 85.7143 %\n",
      "\tTrain Epoch: 5 \tTrain_loss: 1.3183 | Train_acc: 42.5000 % | Validation_loss: 1.2908 | Validation_acc: 85.7143 %\n",
      "\tTrain Epoch: 6 \tTrain_loss: 1.3100 | Train_acc: 40.0000 % | Validation_loss: 1.2927 | Validation_acc: 85.7143 %\n",
      "\tTrain Epoch: 7 \tTrain_loss: 1.3010 | Train_acc: 43.7500 % | Validation_loss: 1.2783 | Validation_acc: 71.4286 %\n",
      "\tTrain Epoch: 8 \tTrain_loss: 1.2934 | Train_acc: 52.5000 % | Validation_loss: 1.2864 | Validation_acc: 57.1429 %\n",
      "\tTrain Epoch: 9 \tTrain_loss: 1.2868 | Train_acc: 48.7500 % | Validation_loss: 1.2804 | Validation_acc: 42.8571 %\n",
      "\tTrain Epoch: 10 \tTrain_loss: 1.2793 | Train_acc: 50.0000 % | Validation_loss: 1.2844 | Validation_acc: 42.8571 %\n",
      "save graph in  results/FHE-cnn-qnn-0d54042f\n",
      "Skipping encryption of layer: features.0.weight\n",
      "Skipping encryption of layer: features.0.bias\n",
      "Skipping encryption of layer: features.3.weight\n",
      "Skipping encryption of layer: features.3.bias\n",
      "Encrypting layer: classifier.0.weight\n",
      "Skipping encryption of layer: classifier.0.bias\n",
      "Skipping encryption of layer: classifier.2.weight\n",
      "Skipping encryption of layer: classifier.2.bias\n",
      "Skipping encryption of layer: classifier.3.weights\n",
      "Skipping encryption of layer: classifier.4.weight\n",
      "Skipping encryption of layer: classifier.4.bias\n",
      "Saving round 2 aggregated_parameters...\n",
      "['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.2.weight', 'classifier.2.bias', 'classifier.3.weights', 'classifier.4.weight', 'classifier.4.bias']\n",
      "Number of aggregated parameters: 11\n",
      "[Client 0] evaluate, config: {}\n",
      "Updated trainable model parameters\n",
      "[Client 0, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '10', 'server_round': 3, 'local_epochs': 10}\n",
      "Updated trainable model parameters\n",
      "\tTrain Epoch: 1 \tTrain_loss: 1.2900 | Train_acc: 43.7500 % | Validation_loss: 1.3025 | Validation_acc: 28.5714 %\n",
      "\tTrain Epoch: 2 \tTrain_loss: 1.2686 | Train_acc: 41.2500 % | Validation_loss: 1.2807 | Validation_acc: 28.5714 %\n",
      "\tTrain Epoch: 3 \tTrain_loss: 1.2561 | Train_acc: 51.2500 % | Validation_loss: 1.2897 | Validation_acc: 42.8571 %\n",
      "\tTrain Epoch: 4 \tTrain_loss: 1.2549 | Train_acc: 48.7500 % | Validation_loss: 1.3009 | Validation_acc: 28.5714 %\n",
      "\tTrain Epoch: 5 \tTrain_loss: 1.2421 | Train_acc: 50.0000 % | Validation_loss: 1.2769 | Validation_acc: 57.1429 %\n",
      "\tTrain Epoch: 6 \tTrain_loss: 1.2384 | Train_acc: 43.7500 % | Validation_loss: 1.2880 | Validation_acc: 14.2857 %\n",
      "\tTrain Epoch: 7 \tTrain_loss: 1.2255 | Train_acc: 48.7500 % | Validation_loss: 1.2826 | Validation_acc: 28.5714 %\n",
      "\tTrain Epoch: 8 \tTrain_loss: 1.2216 | Train_acc: 42.5000 % | Validation_loss: 1.2831 | Validation_acc: 14.2857 %\n",
      "\tTrain Epoch: 9 \tTrain_loss: 1.2107 | Train_acc: 47.5000 % | Validation_loss: 1.2709 | Validation_acc: 28.5714 %\n",
      "\tTrain Epoch: 10 \tTrain_loss: 1.2050 | Train_acc: 43.7500 % | Validation_loss: 1.2614 | Validation_acc: 28.5714 %\n",
      "save graph in  results/FHE-cnn-qnn-0d54042f\n",
      "Skipping encryption of layer: features.0.weight\n",
      "Skipping encryption of layer: features.0.bias\n",
      "Skipping encryption of layer: features.3.weight\n",
      "Skipping encryption of layer: features.3.bias\n",
      "Encrypting layer: classifier.0.weight\n",
      "Skipping encryption of layer: classifier.0.bias\n",
      "Skipping encryption of layer: classifier.2.weight\n",
      "Skipping encryption of layer: classifier.2.bias\n",
      "Skipping encryption of layer: classifier.3.weights\n",
      "Skipping encryption of layer: classifier.4.weight\n",
      "Skipping encryption of layer: classifier.4.bias\n",
      "Saving round 3 aggregated_parameters...\n",
      "['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.2.weight', 'classifier.2.bias', 'classifier.3.weights', 'classifier.4.weight', 'classifier.4.bias']\n",
      "Number of aggregated parameters: 11\n",
      "[Client 0] evaluate, config: {}\n",
      "Updated trainable model parameters\n",
      "Training completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = subprocess.run(\n",
    "    [\"./scripts/experiment.sh\", \"cnn-qnn\", \"--he\"], stdout=subprocess.PIPE\n",
    ")\n",
    "print(result.stdout.decode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encrypted-qfl-VgupAGw-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
