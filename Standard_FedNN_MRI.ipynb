{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset\n",
    "# mkdir data data/MRI\n",
    "# unzip brain-tumor-mri-dataset.zip -d data/MRI\n",
    "# rm brain-tumor-mri-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flwr==1.5.0 in ./.venv/lib64/python3.12/site-packages (1.5.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib64/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib64/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: pennylane in ./.venv/lib64/python3.12/site-packages (0.39.0)\n",
      "Requirement already satisfied: ray>=2.3.0 in ./.venv/lib64/python3.12/site-packages (2.40.0)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib64/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: pillow in ./.venv/lib64/python3.12/site-packages (11.0.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib64/python3.12/site-packages (1.6.0)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib64/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas in ./.venv/lib64/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: opacus in ./.venv/lib64/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib64/python3.12/site-packages (6.0.2)\n",
      "Requirement already satisfied: tenseal in ./.venv/lib64/python3.12/site-packages (0.3.15)\n",
      "Requirement already satisfied: kaggle in ./.venv/lib64/python3.12/site-packages (1.6.17)\n",
      "Requirement already satisfied: cryptography<42.0.0,>=41.0.2 in ./.venv/lib64/python3.12/site-packages (from flwr==1.5.0) (41.0.7)\n",
      "Requirement already satisfied: grpcio!=1.52.0,<2.0.0,>=1.48.2 in ./.venv/lib64/python3.12/site-packages (from flwr==1.5.0) (1.68.1)\n",
      "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in ./.venv/lib64/python3.12/site-packages (from flwr==1.5.0) (0.0.2)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.19.0 in ./.venv/lib64/python3.12/site-packages (from flwr==1.5.0) (3.20.3)\n",
      "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in ./.venv/lib64/python3.12/site-packages (from flwr==1.5.0) (3.21.0)\n",
      "Requirement already satisfied: scipy in ./.venv/lib64/python3.12/site-packages (from pennylane) (1.14.1)\n",
      "Requirement already satisfied: networkx in ./.venv/lib64/python3.12/site-packages (from pennylane) (3.4.2)\n",
      "Requirement already satisfied: rustworkx>=0.14.0 in ./.venv/lib64/python3.12/site-packages (from pennylane) (0.15.1)\n",
      "Requirement already satisfied: autograd in ./.venv/lib64/python3.12/site-packages (from pennylane) (1.7.0)\n",
      "Requirement already satisfied: toml in ./.venv/lib64/python3.12/site-packages (from pennylane) (0.10.2)\n",
      "Requirement already satisfied: appdirs in ./.venv/lib64/python3.12/site-packages (from pennylane) (1.4.4)\n",
      "Requirement already satisfied: autoray>=0.6.11 in ./.venv/lib64/python3.12/site-packages (from pennylane) (0.7.0)\n",
      "Requirement already satisfied: cachetools in ./.venv/lib64/python3.12/site-packages (from pennylane) (5.5.0)\n",
      "Requirement already satisfied: pennylane-lightning>=0.39 in ./.venv/lib64/python3.12/site-packages (from pennylane) (0.39.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib64/python3.12/site-packages (from pennylane) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib64/python3.12/site-packages (from pennylane) (4.12.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib64/python3.12/site-packages (from pennylane) (24.2)\n",
      "Requirement already satisfied: click>=7.0 in ./.venv/lib64/python3.12/site-packages (from ray>=2.3.0) (8.1.7)\n",
      "Requirement already satisfied: filelock in ./.venv/lib64/python3.12/site-packages (from ray>=2.3.0) (3.16.1)\n",
      "Requirement already satisfied: jsonschema in ./.venv/lib64/python3.12/site-packages (from ray>=2.3.0) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in ./.venv/lib64/python3.12/site-packages (from ray>=2.3.0) (1.1.0)\n",
      "Requirement already satisfied: aiosignal in ./.venv/lib64/python3.12/site-packages (from ray>=2.3.0) (1.3.2)\n",
      "Requirement already satisfied: frozenlist in ./.venv/lib64/python3.12/site-packages (from ray>=2.3.0) (1.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib64/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib64/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib64/python3.12/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib64/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib64/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib64/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib64/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib64/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib64/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib64/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: torch>=2.0 in ./.venv/lib64/python3.12/site-packages (from opacus) (2.5.1)\n",
      "Requirement already satisfied: opt-einsum>=3.3.0 in ./.venv/lib64/python3.12/site-packages (from opacus) (3.4.0)\n",
      "Requirement already satisfied: six>=1.10 in ./.venv/lib64/python3.12/site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in ./.venv/lib64/python3.12/site-packages (from kaggle) (2024.12.14)\n",
      "Requirement already satisfied: python-slugify in ./.venv/lib64/python3.12/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in ./.venv/lib64/python3.12/site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: bleach in ./.venv/lib64/python3.12/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in ./.venv/lib64/python3.12/site-packages (from cryptography<42.0.0,>=41.0.2->flwr==1.5.0) (1.17.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (3.1.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib64/python3.12/site-packages (from torch>=2.0->opacus) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib64/python3.12/site-packages (from sympy==1.13.1->torch>=2.0->opacus) (1.3.0)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib64/python3.12/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib64/python3.12/site-packages (from jsonschema->ray>=2.3.0) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib64/python3.12/site-packages (from jsonschema->ray>=2.3.0) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib64/python3.12/site-packages (from jsonschema->ray>=2.3.0) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib64/python3.12/site-packages (from jsonschema->ray>=2.3.0) (0.22.3)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in ./.venv/lib64/python3.12/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib64/python3.12/site-packages (from requests->pennylane) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib64/python3.12/site-packages (from requests->pennylane) (3.10)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib64/python3.12/site-packages (from cffi>=1.12->cryptography<42.0.0,>=41.0.2->flwr==1.5.0) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib64/python3.12/site-packages (from jinja2->torch>=2.0->opacus) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install flwr==1.5.0 tqdm numpy pennylane \"ray>=2.3.0\" matplotlib pillow scikit-learn seaborn pandas opacus pyyaml tenseal kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in ./.venv/lib64/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib64/python3.12/site-packages (0.20.1+cpu)\n",
      "Requirement already satisfied: torchaudio in ./.venv/lib64/python3.12/site-packages (2.5.1+cpu)\n",
      "Requirement already satisfied: filelock in ./.venv/lib64/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib64/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib64/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib64/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib64/python3.12/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib64/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib64/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib64/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib64/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib64/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib64/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib64/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib64/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib64/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib64/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib64/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib64/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.venv/lib64/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib64/python3.12/site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib64/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib64/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib64/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib64/python3.12/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib64/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# cluster stuff\n",
    "#libs_path = \"/home/sc.uni-leipzig.de/dk52ajih/.local/lib/python3.12/site-packages\"\n",
    "#sys.path.append(libs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from typing import (\n",
    "    List, Tuple, Dict, Optional, Callable, Union, cast\n",
    ")\n",
    "import tenseal as ts\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import flwr as fl\n",
    "from flwr.common import (\n",
    "    Metrics, EvaluateIns, EvaluateRes, FitIns, FitRes, MetricsAggregationFn, \n",
    "    Scalar, logger, Parameters, NDArray, NDArrays\n",
    ")\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.strategy.aggregate import weighted_loss_avg\n",
    "from logging import WARNING\n",
    "import pennylane as qml\n",
    "\n",
    "from utils.common import choice_device, classes_string, save_matrix, save_roc, save_graphs, get_parameters2, set_parameters\n",
    "from utils import security, engine, data_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Compatibility of Flower & TenSEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_path = 'secret.pkl'\n",
    "server_path = 'secret.pkl'\n",
    "path_crypted = 'server.pkl'\n",
    "\n",
    "def ndarrays_to_parameters(ndarrays: NDArrays) -> Parameters:\n",
    "    return ndarrays_to_parameters_custom(ndarrays)\n",
    "\n",
    "\n",
    "def parameters_to_ndarrays(parameters: Parameters) -> NDArrays:\n",
    "    with open(secret_path, 'rb') as f:\n",
    "        query = pickle.load(f)\n",
    "\n",
    "    context_client = ts.context_from(query[\"contexte\"])\n",
    "    return parameters_to_ndarrays_custom(parameters, context_client=context_client)\n",
    "\n",
    "\n",
    "def ndarray_to_bytes(ndarray: NDArray) -> bytes:\n",
    "    return ndarray_to_bytes_custom(ndarray)\n",
    "\n",
    "\n",
    "def bytes_to_ndarray(tensor: bytes, context_client) -> NDArray:\n",
    "    bytes_io = BytesIO(tensor)\n",
    "    ndarray_deserialized = np.load(bytes_io, allow_pickle=False)\n",
    "    return cast(NDArray, ndarray_deserialized)\n",
    "\n",
    "\n",
    "def ndarray_to_bytes_custom(ndarray: NDArray) -> bytes:\n",
    "    if type(ndarray) == ts.tensors.CKKSTensor:\n",
    "        return ndarray.serialize()\n",
    "\n",
    "    bytes_io = BytesIO()\n",
    "    np.save(bytes_io, ndarray.cpu().detach().numpy() if type(ndarray) == torch.Tensor else ndarray, allow_pickle=False)\n",
    "    return bytes_io.getvalue()\n",
    "\n",
    "\n",
    "def bytes_to_ndarray_custom(tensor: bytes, context_client) -> NDArray:\n",
    "    try:\n",
    "        ndarray_deserialized = ts.ckks_tensor_from(context_client, tensor)\n",
    "    except:\n",
    "        bytes_io = BytesIO(tensor)\n",
    "        ndarray_deserialized = np.load(bytes_io, allow_pickle=False)\n",
    "\n",
    "    return cast(NDArray, ndarray_deserialized)\n",
    "\n",
    "\n",
    "def ndarrays_to_parameters_custom(ndarrays: NDArrays) -> Parameters:\n",
    "    tensors = [ndarray_to_bytes_custom(ndarray) for ndarray in ndarrays]\n",
    "    return Parameters(tensors=tensors, tensor_type=\"numpy.ndarray\")\n",
    "\n",
    "\n",
    "def parameters_to_ndarrays_custom(parameters: Parameters, context_client) -> NDArrays:\n",
    "    return [bytes_to_ndarray_custom(tensor, context_client) for tensor in parameters.tensors]\n",
    "\n",
    "fl.common.parameter.ndarrays_to_parameters = ndarrays_to_parameters\n",
    "fl.common.parameter.paramaters_to_ndarrays = parameters_to_ndarrays\n",
    "fl.common.parameter.ndarray_to_bytes = ndarray_to_bytes\n",
    "fl.common.parameter.bytes_to_ndarray = bytes_to_ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of FHE Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it exists\n"
     ]
    }
   ],
   "source": [
    "def combo_keys(client_path=\"secret.pkl\", server_path=\"server_key.pkl\"):\n",
    "    \"\"\"\n",
    "    To create the public/private keys combination\n",
    "    args:\n",
    "        client_path: path to save the secret key (str)\n",
    "        server_path: path to save the server public key (str)\n",
    "    \"\"\"\n",
    "    context_client = security.context()\n",
    "    security.write_query(client_path, {\"contexte\": context_client.serialize(save_secret_key=True)})\n",
    "    security.write_query(server_path, {\"contexte\": context_client.serialize()})\n",
    "\n",
    "    _, context_client = security.read_query(client_path)\n",
    "    _, context_server = security.read_query(server_path)\n",
    "\n",
    "    context_client = ts.context_from(context_client)\n",
    "    context_server = ts.context_from(context_server)\n",
    "    print(\"Is the client context private?\", (\"Yes\" if context_client.is_private() else \"No\"))\n",
    "    print(\"Is the server context private?\", (\"Yes\" if context_server.is_private() else \"No\"))\n",
    "\n",
    "\n",
    "secret_path = \"secret.pkl\"\n",
    "public_path = \"server_key.pkl\"\n",
    "if os.path.exists(secret_path):\n",
    "    print(\"it exists\")\n",
    "    _, context_client = security.read_query(secret_path)\n",
    "\n",
    "else:\n",
    "    combo_keys(client_path=secret_path, server_path=public_path)\n",
    "\n",
    "n_qubits = 4\n",
    "n_layers = 6\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=n_qubits) # instead of default.qubit.torch\n",
    "    \n",
    "@qml.qnode(dev, interface='torch')\n",
    "def quantum_net(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits)) \n",
    "    qml.BasicEntanglerLayers(weights,wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple CNN model\n",
    "\n",
    "    Args:\n",
    "        num_classes: An integer indicating the number of classes in the dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 56 * 56, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the neural network\n",
    "        \"\"\"\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the FlowerClient class for federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader, device, batch_size, save_results, matrix_path, roc_path,\n",
    "                 yaml_path, he, classes, context_client):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.cid = cid\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.save_results = save_results\n",
    "        self.matrix_path = matrix_path\n",
    "        self.roc_path = roc_path\n",
    "        self.yaml_path = yaml_path\n",
    "        self.he = he\n",
    "        self.classes = classes\n",
    "        self.context_client = context_client\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters2(self.net, self.context_client)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        server_round = config['server_round']\n",
    "        local_epochs = config['local_epochs']\n",
    "        lr = float(config[\"learning_rate\"])\n",
    "\n",
    "        print(f'[Client {self.cid}, round {server_round}] fit, config: {config}')\n",
    "\n",
    "        set_parameters(self.net, parameters, self.context_client)\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), lr=lr)\n",
    "\n",
    "        results = engine.train(self.net, self.trainloader, self.valloader, optimizer=optimizer, loss_fn=criterion,\n",
    "                               epochs=local_epochs, device=self.device)\n",
    "\n",
    "        if self.save_results:\n",
    "            save_graphs(self.save_results, local_epochs, results, f\"_Client {self.cid}\")\n",
    "\n",
    "        return get_parameters2(self.net, self.context_client), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters, self.context_client)\n",
    "\n",
    "        loss, accuracy, y_pred, y_true, y_proba = engine.test(self.net, self.valloader,\n",
    "                                                              loss_fn=torch.nn.CrossEntropyLoss(), device=self.device)\n",
    "\n",
    "        #if self.save_results:\n",
    "        #    os.makedirs(self.save_results, exist_ok=True)\n",
    "        #    if self.matrix_path:\n",
    "        #        save_matrix(y_true, y_pred, self.save_results + self.matrix_path, self.classes)\n",
    "        #    if self.roc_path:\n",
    "        #        save_roc(y_true, y_proba, self.save_results + self.roc_path, len(self.classes))\n",
    "\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "Checking Serializability of <function FlowerClient.evaluate at 0x7fa017b36ac0>\n",
      "==============================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, set())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"RAY_PICKLE_VERBOSE_DEBUG\"] = '2'\n",
    "from ray.util import inspect_serializability\n",
    "\n",
    "inspect_serializability(FlowerClient.evaluate, name=\"evaluate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the client_common function to set up the Flower client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_common(cid, model_save, path_yaml, path_roc, results_save, path_matrix,\n",
    "                  batch_size, trainloaders, valloaders, DEVICE, CLASSES,\n",
    "                  he=False, secret_path=\"\", server_path=\"\"):\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    context_client = None\n",
    "    net = Net(num_classes=len(CLASSES)).to(DEVICE)\n",
    "\n",
    "    if he:\n",
    "        print(\"Run with homomorphic encryption\")\n",
    "        if os.path.exists(secret_path):\n",
    "            with open(secret_path, 'rb') as f:\n",
    "                query = pickle.load(f)\n",
    "            context_client = ts.context_from(query[\"contexte\"])\n",
    "        else:\n",
    "            context_client = security.context()\n",
    "            with open(secret_path, 'wb') as f:\n",
    "                encode = pickle.dumps({\"contexte\": context_client.serialize(save_secret_key=True)})\n",
    "                f.write(encode)\n",
    "        secret_key = context_client.secret_key()\n",
    "    else:\n",
    "        print(\"Run WITHOUT homomorphic encryption\")\n",
    "\n",
    "    if os.path.exists(model_save):\n",
    "        print(\" To get the checkpoint\")\n",
    "        checkpoint = torch.load(model_save, map_location=DEVICE)['model_state_dict']\n",
    "        if he:\n",
    "            print(\"to decrypt model\")\n",
    "            server_query, server_context = security.read_query(server_path)\n",
    "            server_context = ts.context_from(server_context)\n",
    "            for name in checkpoint:\n",
    "                print(name)\n",
    "                checkpoint[name] = torch.tensor(\n",
    "                    security.deserialized_layer(name, server_query[name], server_context).decrypt(secret_key)\n",
    "                )\n",
    "        net.load_state_dict(checkpoint)\n",
    "\n",
    "    return FlowerClient(cid, net, trainloader, valloader, device=DEVICE, batch_size=batch_size,\n",
    "                        matrix_path=path_matrix, roc_path=path_roc, save_results=results_save, yaml_path=path_yaml,\n",
    "                        he=he, context_client=context_client, classes=CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions for federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "def evaluate2(server_round: int, parameters: NDArrays,\n",
    "              config: Dict[str, Scalar]) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "    set_parameters(central, parameters)\n",
    "    loss, accuracy, y_pred, y_true, y_proba = engine.test(central, testloader, loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                                                          device=DEVICE)\n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "def get_on_fit_config_fn(epoch=2, lr=0.001, batch_size=32) -> Callable[[int], Dict[str, str]]:\n",
    "    def fit_config(server_round: int) -> Dict[str, str]:\n",
    "        config = {\n",
    "            \"learning_rate\": str(lr),\n",
    "            \"batch_size\": str(batch_size),\n",
    "            \"server_round\": server_round,\n",
    "            \"local_epochs\": epoch\n",
    "        }\n",
    "        return config\n",
    "    return fit_config\n",
    "\n",
    "def aggreg_fit_checkpoint(server_round, aggregated_parameters, central_model, path_checkpoint,\n",
    "                          context_client=None, server_path=\"\"):\n",
    "    if aggregated_parameters is not None:\n",
    "        print(f\"Saving round {server_round} aggregated_parameters...\")\n",
    "        aggregated_ndarrays: List[np.ndarray] = parameters_to_ndarrays_custom(aggregated_parameters, context_client)\n",
    "        if context_client:   \n",
    "            server_response = {\"contexte\": server_context.serialize()}\n",
    "            for i, key in enumerate(central_model.state_dict().keys()):\n",
    "                try:\n",
    "                    server_response[key] = aggregated_ndarrays[i].serialize()\n",
    "                except:\n",
    "                    server_response[key] = aggregated_ndarrays[i]\n",
    "            security.write_query(server_path, server_response)\n",
    "        else:\n",
    "            params_dict = zip(central_model.state_dict().keys(), aggregated_ndarrays)\n",
    "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "            central_model.load_state_dict(state_dict, strict=True)\n",
    "            if path_checkpoint:\n",
    "                torch.save({\n",
    "                    'model_state_dict': central_model.state_dict(),\n",
    "                }, path_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the FedCustom strategy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Strategy from scratch with the same sampling of the clients as it is in FedAvg\n",
    "# and then change the configuration dictionary\n",
    "class FedCustom(fl.server.strategy.Strategy):\n",
    "    def __init__(\n",
    "            self,\n",
    "            fraction_fit: float = 1.0,\n",
    "            fraction_evaluate: float = 1.0,\n",
    "            min_fit_clients: int = 2,\n",
    "            min_evaluate_clients: int = 2,\n",
    "            min_available_clients: int = 2,\n",
    "            evaluate_fn: Optional[\n",
    "                    Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]\n",
    "                ] = None,\n",
    "            on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "            on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "            accept_failures: bool = True,\n",
    "            initial_parameters: Optional[Parameters] = None,\n",
    "            fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "            evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "            context_client=None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.on_fit_config_fn = on_fit_config_fn\n",
    "        self.on_evaluate_config_fn = on_evaluate_config_fn,\n",
    "        self.accept_failures = accept_failures\n",
    "        self.initial_parameters = initial_parameters\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
    "        self.context_client = context_client\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        return f\"FedCustom (accept_failures={self.accept_failures})\"\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        initial_parameters = self.initial_parameters\n",
    "        self.initial_parameters = None  # Don't keep initial parameters in memory\n",
    "        return initial_parameters\n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "        # Create custom configs\n",
    "        n_clients = len(clients)\n",
    "        half_clients = n_clients // 2\n",
    "        # Custom fit config function provided\n",
    "        standard_lr = lr\n",
    "        higher_lr = 0.003\n",
    "        config = {\"server_round\": server_round, \"local_epochs\": 1}\n",
    "        if self.on_fit_config_fn is not None:\n",
    "            # Custom fit config function provided\n",
    "            config = self.on_fit_config_fn(server_round)\n",
    "\n",
    "        # fit_ins = FitIns(parameters, config)\n",
    "        # Return client/config pairs\n",
    "        fit_configurations = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            config[\"learning_rate\"] = standard_lr if idx < half_clients else higher_lr\n",
    "            \"\"\"\n",
    "            Each pair of (ClientProxy, FitRes) constitutes \n",
    "            a successful update from one of the previously selected clients.\n",
    "            \"\"\"\n",
    "            fit_configurations.append(\n",
    "                (\n",
    "                    client,\n",
    "                    FitIns(\n",
    "                        parameters,\n",
    "                        config\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        # Successful updates from the previously selected and configured clients\n",
    "        return fit_configurations\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average. (each round)\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Do not aggregate if there are failures and failures are not accepted\n",
    "        if not self.accept_failures and failures:\n",
    "            return None, {}\n",
    "\n",
    "        # Convert results parameters --> array matrix\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays_custom(fit_res.parameters, self.context_client), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "\n",
    "        # Aggregate parameters using weighted average between the clients and convert back to parameters object (bytes)\n",
    "        parameters_aggregated = ndarrays_to_parameters_custom(security.aggregate_custom(weights_results))\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        # Aggregate custom metrics if aggregation fn was provided\n",
    "        if self.fit_metrics_aggregation_fn:\n",
    "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
    "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
    "\n",
    "        elif server_round == 1:  # Only log this warning once\n",
    "            logger.log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
    "\n",
    "        # Same function as SaveModelStrategy(fl.server.strategy.FedAvg)\n",
    "        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
    "        aggreg_fit_checkpoint(server_round, parameters_aggregated, central, model_save,\n",
    "                              self.context_client, path_crypted)\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        # Do not configure federated evaluation if fraction eval is 0.\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "\n",
    "        # Parameters and config\n",
    "        config = {}  # {\"server_round\": server_round, \"local_epochs\": 1}\n",
    "\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        # Each pair of (ClientProxy, FitRes) constitutes a successful update from one of the previously selected clients\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Do not aggregate if there are failures and failures are not accepted\n",
    "        if not self.accept_failures and failures:\n",
    "            return None, {}\n",
    "\n",
    "        # Aggregate loss\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        # Aggregate custom metrics if aggregation fn was provided\n",
    "        if self.evaluate_metrics_aggregation_fn:\n",
    "            eval_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
    "            metrics_aggregated = self.evaluate_metrics_aggregation_fn(eval_metrics)\n",
    "\n",
    "        # Only log this warning once\n",
    "        elif server_round == 1:\n",
    "            logger.log(WARNING, \"No evaluate_metrics_aggregation_fn provided\")\n",
    "\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate global model parameters using an evaluation function.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if self.evaluate_fn is None:\n",
    "            # Let's assume we won't perform the global model evaluation on the server side.\n",
    "            return None\n",
    "\n",
    "        # if we have a global model evaluation on the server side :\n",
    "        parameters_ndarrays = parameters_to_ndarrays_custom(parameters, self.context_client)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "\n",
    "        # if you haven't results\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "\n",
    "        loss, metrics = eval_res\n",
    "        return loss, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the federated learning strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your variables directly\n",
    "he = False\n",
    "data_path = 'data-tiny/'\n",
    "dataset = 'MRI' # 'MRI'\n",
    "yaml_path = './results/FL/results.yml'\n",
    "seed = 0\n",
    "num_workers = 0\n",
    "max_epochs = 10\n",
    "batch_size = 10 # 32\n",
    "splitter = 10\n",
    "device = 'gpu'\n",
    "number_clients = 1 # 10\n",
    "save_results = 'results/FL/'\n",
    "matrix_path = 'confusion_matrix.png'\n",
    "roc_path = 'roc.png'\n",
    "model_save = 'MRI_fl.pt'\n",
    "min_fit_clients = 1 # 10\n",
    "min_avail_clients = 1 # 10\n",
    "min_eval_clients = 1 # 10\n",
    "rounds = 20\n",
    "frac_fit = 1.0\n",
    "frac_eval = 0.5\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('glioma', 'meningioma', 'notumor', 'pituitary')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_string(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_context = None\n",
    "DEVICE = torch.device(choice_device(device))\n",
    "CLASSES = classes_string(dataset)\n",
    "central = Net(num_classes=len(CLASSES)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = FedCustom(\n",
    "    fraction_fit=frac_fit,\n",
    "    fraction_evaluate=frac_eval,\n",
    "    min_fit_clients=min_fit_clients,\n",
    "    min_evaluate_clients=min_eval_clients if min_eval_clients else number_clients // 2,\n",
    "    min_available_clients=min_avail_clients,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    "    initial_parameters=ndarrays_to_parameters_custom(get_parameters2(central)),\n",
    "    evaluate_fn=None if he else evaluate2,\n",
    "    on_fit_config_fn=get_on_fit_config_fn(epoch=max_epochs, batch_size=batch_size),\n",
    "    context_client=server_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI\n",
      "The training set is created for the classes : ['glioma', 'meningioma', 'notumor', 'pituitary']\n"
     ]
    }
   ],
   "source": [
    "trainloaders, valloaders, testloader = data_setup.load_datasets(num_clients=number_clients,\n",
    "                                                                batch_size=batch_size,\n",
    "                                                                resize=224,\n",
    "                                                                seed=seed,\n",
    "                                                                num_workers=num_workers,\n",
    "                                                                splitter=splitter,\n",
    "                                                                dataset=dataset,  # Use the specified dataset\n",
    "                                                                data_path=data_path,\n",
    "                                                                data_path_val=None)  # Use the same path for validation data\n",
    "\n",
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    return client_common(cid,\n",
    "                         model_save, path_yaml, path_roc, results_save, path_matrix,\n",
    "                         batch_size, trainloaders, valloaders, DEVICE, CLASSES, he, secret_path, server_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the client_fn function and set up the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flwr 1.5.0\n",
      "numpy 1.26.4\n",
      "torch 2.5.1+cu124\n",
      "torchvision 0.20.1+cpu\n",
      "Training on cpu\n",
      "Start simulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-12-20 20:07:26,211 | app.py:175 | Starting Flower simulation, config: ServerConfig(num_rounds=20, round_timeout=None)\n",
      "2024-12-20 20:07:27,351\tINFO worker.py:1821 -- Started a local Ray instance.\n",
      "INFO flwr 2024-12-20 20:07:28,391 | app.py:210 | Flower VCE: Ray initialized with resources: {'CPU': 6.0, 'node:__internal_head__': 1.0, 'memory': 5403832320.0, 'object_store_memory': 2701916160.0, 'node:172.18.123.232': 1.0}\n",
      "INFO flwr 2024-12-20 20:07:28,392 | app.py:224 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 0}\n",
      "INFO flwr 2024-12-20 20:07:28,405 | app.py:270 | Flower VCE: Creating VirtualClientEngineActorPool with 3 actors\n",
      "INFO flwr 2024-12-20 20:07:28,406 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-12-20 20:07:28,407 | server.py:272 | Using initial parameters provided by strategy\n",
      "INFO flwr 2024-12-20 20:07:28,408 | server.py:91 | Evaluating initial parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated model\n",
      "Server-side evaluation loss 1.3835658133029938 / accuracy 45.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-12-20 20:07:29,271 | server.py:94 | initial parameters (loss, other metrics): 1.3835658133029938, {'accuracy': 45.0}\n",
      "INFO flwr 2024-12-20 20:07:29,272 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-12-20 20:07:29,272 | server.py:222 | fit_round 1: strategy sampled 1 clients (out of 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DefaultActor pid=39461) Run WITHOUT homomorphic encryption\n",
      "(DefaultActor pid=39461) [Client 0, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '10', 'server_round': 1, 'local_epochs': 10}\n",
      "(DefaultActor pid=39461) Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|ultActor pid=39461)           | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DefaultActor pid=39461) \tTrain Epoch: 1 \tTrain_loss: 13.5788 | Train_acc: 41.2500 % | Validation_loss: 0.8123 | Validation_acc: 57.1429 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|ultActor pid=39461) █         | 1/10 [00:02<00:19,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DefaultActor pid=39461) \tTrain Epoch: 2 \tTrain_loss: 0.3555 | Train_acc: 87.5000 % | Validation_loss: 0.5256 | Validation_acc: 85.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|ultActor pid=39461) ██        | 2/10 [00:04<00:16,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DefaultActor pid=39461) \tTrain Epoch: 3 \tTrain_loss: 0.0666 | Train_acc: 96.2500 % | Validation_loss: 3.4584 | Validation_acc: 57.1429 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|ultActor pid=39461) ███       | 3/10 [00:05<00:13,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DefaultActor pid=39461) \tTrain Epoch: 4 \tTrain_loss: 0.0065 | Train_acc: 100.0000 % | Validation_loss: 2.5763 | Validation_acc: 71.4286 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|ultActor pid=39461) ████      | 4/10 [00:07<00:11,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DefaultActor pid=39461) \tTrain Epoch: 5 \tTrain_loss: 0.0283 | Train_acc: 98.7500 % | Validation_loss: 0.9504 | Validation_acc: 85.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|ultActor pid=39461) █████     | 5/10 [00:09<00:09,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DefaultActor pid=39461) \tTrain Epoch: 6 \tTrain_loss: 0.1498 | Train_acc: 96.2500 % | Validation_loss: 0.0941 | Validation_acc: 100.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|ultActor pid=39461) ██████    | 6/10 [00:11<00:07,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DefaultActor pid=39461) \tTrain Epoch: 7 \tTrain_loss: 0.0001 | Train_acc: 100.0000 % | Validation_loss: 0.1490 | Validation_acc: 85.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|ultActor pid=39461) ███████   | 7/10 [00:13<00:05,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DefaultActor pid=39461) \tTrain Epoch: 8 \tTrain_loss: 0.0635 | Train_acc: 98.7500 % | Validation_loss: 0.0175 | Validation_acc: 100.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|ultActor pid=39461) ████████  | 8/10 [00:15<00:03,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DefaultActor pid=39461) \tTrain Epoch: 9 \tTrain_loss: 0.0028 | Train_acc: 100.0000 % | Validation_loss: 0.1217 | Validation_acc: 85.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|ultActor pid=39461) █████████ | 9/10 [00:17<00:01,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DefaultActor pid=39461) \tTrain Epoch: 10 \tTrain_loss: 0.0032 | Train_acc: 100.0000 % | Validation_loss: 0.4646 | Validation_acc: 85.7143 %\n",
      "(DefaultActor pid=39461) save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ultActor pid=39461) ██████████| 10/10 [00:19<00:00,  1.93s/it]██████████| 10/10 [00:19<00:00,  1.92s/it]\n",
      "DEBUG flwr 2024-12-20 20:07:52,379 | server.py:236 | fit_round 1 received 1 results and 0 failures\n",
      "ERROR flwr 2024-12-20 20:07:52,394 | app.py:294 | name 'aggregate_custom' is not defined\n",
      "ERROR flwr 2024-12-20 20:07:52,395 | app.py:295 | Your simulation crashed :(. This could be because of several reasons.The most common are: \n",
      "\t > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.\n",
      "\t > All the actors in your pool crashed. This could be because: \n",
      "\t\t - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 2, 'num_gpus': 0} is not enough for your workload). Use fewer concurrent actors. \n",
      "\t\t - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 2, 'num_gpus': 0}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation Time = 26.20849370956421 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"torchvision\", torchvision.__version__)\n",
    "print(f\"Training on {DEVICE}\")\n",
    "\n",
    "client_resources = {\"num_cpus\":2, \"num_gpus\":0}\n",
    "\n",
    "if DEVICE.type == \"cuda\":\n",
    "    client_resources = {\"num_gpus\": 1}\n",
    "\n",
    "model_save = model_save\n",
    "path_yaml = yaml_path\n",
    "path_roc = roc_path\n",
    "results_save = save_results\n",
    "path_matrix = matrix_path\n",
    "batch_size = batch_size\n",
    "he = he\n",
    "secret_path = 'secret.pkl'\n",
    "server_path = 'server_key.pkl'\n",
    "path_crypted = 'server.pkl'\n",
    "\n",
    "print(\"Start simulation\")\n",
    "start_simulation = time.time()\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=number_clients,\n",
    "    config=fl.server.ServerConfig(num_rounds=rounds),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources\n",
    ")\n",
    "print(f\"Simulation Time = {time.time() - start_simulation} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
